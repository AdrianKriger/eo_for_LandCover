{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the Training data\n",
    "---\n",
    "\n",
    "\n",
    "We will create a new workflow that processes the data:\n",
    "\n",
    "1. Remove too cloudy scenes\n",
    "   * Check the ratio of the valid data for each patch and for each time frame\n",
    "   * Keep only > 80 % valid coverage\n",
    "2. Concatenate BAND, NDVI, NDWI, NDBI info into a single feature called FEATURES\n",
    "3. As this example only covers one image taken on one day; ```Linear Interpolation``` is not done. For larger time periods it would be.\n",
    "   * Perform temporal Interpolation\n",
    "   * Create a task for linear interpolation in the temporal dimension\n",
    "   * Provide the cloud mask to tell the interpolating function which values to update```\n",
    "4. Perform erosion\n",
    "   * This removes artefacts with a width of 1 px, and also removes the edges between polygons of different classes\n",
    "5. Random spatial sampling of the EOPatches\n",
    "   * Randomly take a subset of pixels from a patch to use in the machine learning training\n",
    "6. Split patches for training/validation\n",
    "   * Split the patches into a training and validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "import pickle\n",
    "\n",
    "# Basics of Python data handling and visualization\n",
    "import itertools\n",
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "import geopandas as gpd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap, BoundaryNorm\n",
    "from IPython.display import Image \n",
    "\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from aenum import MultiValueEnum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports from eo-learn and sentinelhub-py\n",
    "from eolearn.core import EOTask, EOPatch, LinearWorkflow, FeatureType, OverwritePermission, LoadTask, SaveTask, EOExecutor, ExtractBandsTask, MergeFeatureTask\n",
    "from eolearn.geometry import VectorToRaster, PointSamplingTask, ErosionTask\n",
    "from eolearn.features import LinearInterpolation, SimpleFilterTask, NormalizedDifferenceIndexTask\n",
    "from sentinelhub import UtmZoneSplitter, BBox, CRS, DataSource"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Machine learning \n",
    "import lightgbm as lgb\n",
    "#import joblib\n",
    "from sklearn.externals import joblib\n",
    "from sklearn import metrics\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "path = Path('./')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ValidDataFractionPredicate:\n",
    "    \"\"\"\n",
    "    Predicate that defines if a frame from EOPatch's time-series is valid or not. Frame is valid, if the \n",
    "    valid data fraction is above the specified threshold.\n",
    "    \"\"\"\n",
    "    def __init__(self, threshold):\n",
    "        self.threshold = threshold\n",
    "        \n",
    "    def __call__(self, array):\n",
    "        coverage = np.sum(array.astype(np.uint8)) / np.prod(array.shape)\n",
    "        return coverage > self.threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_out = './data/eopatches'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TASK TO LOAD EXISTING EOPATCHES\n",
    "load = LoadTask(path_out)\n",
    "\n",
    "# TASK FOR CONCATENATION\n",
    "concatenate = MergeFeatureTask({FeatureType.DATA: ['BANDS', 'NDVI', 'NDWI', 'NDBI']},\n",
    "                               (FeatureType.DATA, 'FEATURES'))\n",
    "\n",
    "# TASK FOR FILTERING OUT TOO CLOUDY SCENES\n",
    "# keep frames with > 80 % valid coverage\n",
    "valid_data_predicate = ValidDataFractionPredicate(0.8)\n",
    "filter_task = SimpleFilterTask((FeatureType.MASK, 'IS_VALID'), valid_data_predicate)\n",
    "\n",
    "# TASK FOR LINEAR INTERPOLATION\n",
    "# linear interpolation of full time-series and date resampling\n",
    "resampled_range = ('2020-02-28', '2020-03-02', 3)\n",
    "linear_interp = LinearInterpolation(\n",
    "    'FEATURES', # name of field to interpolate\n",
    "    mask_feature=(FeatureType.MASK, 'IS_VALID'), # mask to be used in interpolation\n",
    "    copy_features=[(FeatureType.MASK_TIMELESS, 'LndC')], # features to keep\n",
    "    resample_range=resampled_range, # set the resampling range\n",
    "    bounds_error=False # extrapolate with NaN's\n",
    ")\n",
    "\n",
    "# TASK FOR EROSION\n",
    "# erode each class of the reference map\n",
    "erosion = ErosionTask(mask_feature=(FeatureType.MASK_TIMELESS,'LndC','LndC_ERODED'), disk_radius=1)\n",
    "\n",
    "# TASK FOR SPATIAL SAMPLING\n",
    "# Uniformly sample about pixels from patches\n",
    "n_samples = 125000 # half of pixels\n",
    "ref_labels = list(range(18)) # reference labels to take into account when sampling\n",
    "spatial_sampling = PointSamplingTask(\n",
    "    n_samples=n_samples, \n",
    "    ref_mask_feature='LndC_ERODED', \n",
    "    ref_labels=ref_labels, \n",
    "    sample_features=[  # tag fields to sample\n",
    "        (FeatureType.DATA, 'FEATURES'),\n",
    "        (FeatureType.MASK_TIMELESS, 'LndC_ERODED')\n",
    "    ])\n",
    "\n",
    "path_out_sampled = './data/eopatches_sampled'\n",
    "if not os.path.isdir(path_out_sampled):\n",
    "    os.makedirs(path_out_sampled)\n",
    "save = SaveTask(path_out_sampled, overwrite_permission=OverwritePermission.OVERWRITE_PATCH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the workflow\n",
    "workflow = LinearWorkflow(\n",
    "    load,\n",
    "    concatenate,\n",
    "    filter_task,\n",
    "    #linear_interp,\n",
    "    erosion,\n",
    "    spatial_sampling,\n",
    "    save\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the EOWorkflow over all EOPatches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the patchIDs from the previous notebook\n",
    "#load array\n",
    "fp = os.path.join(path/'data'/'tile-def/', 'patchIDs.csv')\n",
    "patchIDs = np.fromfile(fp, dtype=int)\n",
    "# print the array\n",
    "print(patchIDs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "   \n",
    "execution_args = []\n",
    "for idx in patchIDs:\n",
    "    execution_args.append({\n",
    "        load: {'eopatch_folder': f'eopatch_{idx}'},\n",
    "        spatial_sampling: {'seed': 42},\n",
    "        save: {'eopatch_folder': f'eopatch_{idx}'}\n",
    "    })\n",
    "    \n",
    "executor = EOExecutor(workflow, execution_args, save_logs=False)\n",
    "executor.run(workers=1, multiprocess=False)\n",
    "\n",
    "executor.make_report()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model construction and training\n",
    "\n",
    "The patches are split into a ```train``` and ```test``` subsets.\n",
    "\n",
    "Because of the small area the ```test``` sample in hand picked. With a large dataset, the training and testing patches should be randomly chosen.\n",
    "\n",
    "The sampled features and labels are loaded and reshaped into $n \\times m$, where $n$ represents the number of training pixels, and $m = f \\times t$ the number of all features, with $f$ the size of bands and band combinations (in this example 9) and $t$ the length of the resampled time-series (in this example 1)\n",
    "\n",
    "[LightGBM](https://github.com/Microsoft/LightGBM) is used as the Machine Learning model taken directly from the [eo-learn](https://eo-learn.readthedocs.io/en/latest/examples/land-cover-map/SI_LULC_pipeline.html#6.-Model-construction-and-training) example. Near default hyper-parameters are used. [Parameter tuning](https://lightgbm.readthedocs.io/en/latest/Parameters-Tuning.html) is possible and suggestions are welcome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load sampled eopatches\n",
    "eopatches = []\n",
    "path_out_sampled = './data/eopatches_sampled'\n",
    "\n",
    "for idx in patchIDs:\n",
    "    eopatches.append(EOPatch.load(f'{path_out_sampled}/eopatch_{idx}', lazy_loading=True))    \n",
    "\n",
    "eopatches = np.array(eopatches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(eopatches.shape, eopatches.ndim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definition of the train and test patch IDs, take 80 % for train\n",
    "#NB: it wants the index not the grid number\n",
    "test_ID = [5, 8, 16, 22, 19]\n",
    "train_ID = np.argwhere(~np.in1d(patchIDs, patchIDs[test_ID])).squeeze(axis=-1)\n",
    "\n",
    "# Set the features and the labels for train and test sets\n",
    "features_train = np.array([eopatch.data['FEATURES_SAMPLED'] for eopatch in eopatches[train_ID]])\n",
    "labels_train = np.array([eopatch.mask_timeless['LndC_ERODED_SAMPLED'] for eopatch in eopatches[train_ID]])\n",
    "features_test = np.array([eopatch.data['FEATURES_SAMPLED'] for eopatch in eopatches[test_ID]])\n",
    "labels_test = np.array([eopatch.mask_timeless['LndC_ERODED_SAMPLED'] for eopatch in eopatches[test_ID]])\n",
    "\n",
    "#get shape\n",
    "p1, t, w, h, f = features_train.shape\n",
    "p2, t, w, h, f = features_test.shape\n",
    "p = p1 + p2\n",
    "\n",
    "# reshape to n x m\n",
    "features_train = np.moveaxis(features_train, 1, 3).reshape(p1 * w * h, t * f)\n",
    "#features_train = np.reshape(p1 * w * h, t * f)\n",
    "labels_train = np.moveaxis(labels_train, 1, 2).reshape(p1 * w * h, 1).squeeze()\n",
    "#labels_train = np.reshape(p1 * w * h, 1).squeeze()\n",
    "features_test = np.moveaxis(features_test, 1, 3).reshape(p2 * w * h, t * f)\n",
    "#features_test = np.reshape(p2 * w * h, t * f)\n",
    "labels_test = np.moveaxis(labels_test, 1, 2).reshape(p2 * w * h, 1).squeeze()\n",
    "#labels_test = np.reshape(p2 * w * h, 1).squeeze()\n",
    "\n",
    "# remove points with no reference from training (so we dont train to recognize \"no data\")\n",
    "mask_train = labels_train == 0\n",
    "features_train = features_train[~mask_train]\n",
    "labels_train = labels_train[~mask_train]\n",
    "\n",
    "# remove points with no reference from test (so we dont validate on \"no data\", which doesn't make sense)\n",
    "mask_test = labels_test == 0\n",
    "features_test = features_test[~mask_test]\n",
    "labels_test = labels_test[~mask_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check tht test and training labels went through - remember there are 16 land cover classes\n",
    "print(len(np.unique(labels_test)), len(np.unique(labels_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the shape of the features: in this example - the '9' represents the bands\n",
    "# if we had a larger time period it would change the shape. The 9 would be greater.\n",
    "features_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up and train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Set up training classes\n",
    "labels_unique = np.unique(labels_train)\n",
    "\n",
    "# Set up the model\n",
    "model = lgb.LGBMClassifier(boosting_type = 'dart',\n",
    "    num_leaves = 50,\n",
    "    objective ='multiclass', \n",
    "    learning_rate = 0.07,\n",
    "    num_class =len(labels_unique), \n",
    "    metric = 'multi_logloss',\n",
    "    random_state = 42,\n",
    "    min_data_in_leaf = 1000,\n",
    "    max_depth = 7,\n",
    "    lambda_l1 =  0.5, # L1 regularization.\n",
    "    lambda_l2 = 0.5, # L2 regularization.# stores validation results.\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model\n",
    "model.fit(features_train, labels_train)\n",
    "\n",
    "# uncomment to save the model\n",
    "joblib.dump(model, './model_SI_LndC.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to validate the model, we use the training set to predict the classes, and then compare the predicted set of labels to the **\"ground truth\"**.\n",
    "\n",
    "Our **\"ground truth\"** is a derivative of the 2018 South African National Land Cover; which is a 10-meter accurate product. \n",
    "\n",
    "As per remote sensing standards; validation is performed by evaluating metrics, such as accuracy, precision, recall, $F_1$ score. Nicely described [in this blog post](https://medium.com/greyatom/performance-metrics-for-classification-problems-in-machine-learning-part-i-b085d432082b)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the model\n",
    "model_path = './model_SI_LndC.pkl'\n",
    "model = joblib.load(model_path)\n",
    "\n",
    "# predict the test labels\n",
    "plabels_test = model.predict(features_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the overall accuracy (OA) and the weighted $F_1$ score and the $F_1$ score, precision, and recall for each class separately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the LandCover classes\n",
    "class LndC(MultiValueEnum):\n",
    "    \"\"\" \n",
    "    Enum class containing LandCover types\n",
    "    \"\"\"\n",
    "    Woodland_and_Forest             = 'Woodland and Forest',  1, '#008000'\n",
    "    Shrub_and_Grassland             = 'Shrub and Grassland)', 2, '#9370DB'\n",
    "    Water                           = 'Water',                3, '#000080'\n",
    "    Mines                           = 'Mines',                4, '#8B0000'\n",
    "    Wetlands                        = 'Wetlands',             5, '#00CED1'\n",
    "    Bare_Non_Vegetated              = 'Bare Non-Vegetated',   6, '#FFFACD'\n",
    "    Cultivated_Commercial           = 'Cultivated_Commercial',7, '#DC143C'\n",
    "    Fallow_land                     = 'Fallow land',          8, '#F08080'\n",
    "    Formal_Residential              = 'Formal Residential',   9, '#FFA500'\n",
    "    Informal_Residential            = 'Informal Residential', 10, '#FF69B4'\n",
    "    Village                         = 'Village',              11, '#FF8C00'\n",
    "    Smallholding                    = 'Smallholding',         12, '#DDA0DD'\n",
    "    Urban_Recreation                = 'Urban Recreation',     13, '#7FFF00'\n",
    "    Commercial                      = 'Commercial',           14, '#DAA520'\n",
    "    Industrial                      = 'Industrial',           15, '#B8860B'\n",
    "    Major_Road_and_Rail             = 'Major Road and Rail',  16, '#FFD700'\n",
    "    \n",
    "    @property\n",
    "    def id(self):\n",
    "        \"\"\" Returns an ID of an enum type\n",
    "        :return: An ID\n",
    "        :rtype: int\n",
    "        \"\"\"\n",
    "        return self.values[1]\n",
    "\n",
    "    @property\n",
    "    def color(self):\n",
    "        \"\"\" Returns class color\n",
    "        :return: A color in hexadecimal representation\n",
    "        :rtype: str\n",
    "        \"\"\"\n",
    "        return self.values[2]\n",
    "\n",
    "def get_bounds_from_ids(ids):\n",
    "    bounds = []\n",
    "    for i in range(len(ids)):\n",
    "        if i < len(ids) - 1:\n",
    "            if i == 0:\n",
    "                diff = (ids[i + 1] - ids[i]) / 2\n",
    "                bounds.append(ids[i] - diff)\n",
    "            diff = (ids[i + 1] - ids[i]) / 2\n",
    "            bounds.append(ids[i] + diff)\n",
    "        else:\n",
    "            diff = (ids[i] - ids[i - 1]) / 2\n",
    "            bounds.append(ids[i] + diff)\n",
    "    return bounds \n",
    "\n",
    "# Reference colormap things\n",
    "lulc_bounds = get_bounds_from_ids([x.id for x in LndC])\n",
    "lulc_cmap = ListedColormap([x.color for x in LndC], name=\"lulc_cmap\")\n",
    "lulc_norm = BoundaryNorm(lulc_bounds, lulc_cmap.N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class_labels = np.unique(labels_test)\n",
    "class_names = np.array([entry.name for entry in LndC])\n",
    "mask = np.in1d(plabels_test, labels_test)\n",
    "pred = plabels_test[mask]\n",
    "lbls = labels_test[mask]\n",
    "\n",
    "f1_scores = metrics.f1_score(lbls, pred, labels=class_labels, average=None)\n",
    "recall = metrics.recall_score(lbls, pred, labels=class_labels, average=None)\n",
    "precision = metrics.precision_score(lbls, pred, labels=class_labels, average=None)\n",
    "\n",
    "print('Classification accuracy {:.1f}%'.format(100 * metrics.accuracy_score(lbls, pred)))\n",
    "print('Classification F1-score {:.1f}%'.format(100 * metrics.f1_score(lbls, pred, average='weighted')))\n",
    "print()\n",
    "print('             Class                   =  F1  | Recall  | Precision')\n",
    "print('         --------------------------------------------------')\n",
    "for idx in class_labels:\n",
    "    print('         * {0:25s} = {1:4.1f} |  {2:4.1f}  | {3:3.1f}'.format(class_names[idx - 1], \n",
    "                                                                         f1_scores[idx - 1] * 100, \n",
    "                                                                         recall[idx - 1] * 100, \n",
    "                                                                         precision[idx - 1] * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image](figs/F1RecPrec.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#write the printout to a csv via pandas\n",
    "df = {'Labels' : pd.Series(class_labels), \n",
    "      'Classes' : pd.Series(class_names),      \n",
    "      'F1' : pd.Series(f1_scores), \n",
    "      'Recall' : pd.Series(recall),\n",
    "      'Precision' : pd.Series(precision)}\n",
    "df = pd.DataFrame(df)\n",
    "\n",
    "df.to_csv('./data/f1_recall_precision.csv', ';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>STOP:</b> \n",
    "\n",
    "The results might not seem stella: but it could be down to the classes chosen. I should have merged Smallholding and Village. I could possibly have combined Fallow_land with Bare_Non-Vegetated as well (the Confusion Matrix below confirms this). Also its difficult for an algorithm to know the difference between Urban_Recreation and Grassland; which might appear similar. The same goes for the Industrial and Commercial classes. We're really at the boarder of \"Land-Use\" and Land-Cover. Iether way; its a good test.\n",
    "    \n",
    "```[Parameter Tuning]```(https://lightgbm.readthedocs.io/en/latest/Parameters-Tuning.html) might also achieve a better result,\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the standard and transposed Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the plotting function\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=True,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues, ylabel='True label', xlabel='Predicted label', filename=None):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    np.set_printoptions(precision=2, suppress=True)\n",
    "    \n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / (cm.sum(axis=1)[:, np.newaxis] + np.finfo(np.float).eps)\n",
    "    \n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap, vmin=0, vmax=1)\n",
    "    plt.title(title, fontsize=11)\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=90, fontsize=9)\n",
    "    plt.yticks(tick_marks, classes, fontsize=9)\n",
    "    \n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\",\n",
    "                 fontsize=8)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel(ylabel, fontsize=12)\n",
    "    plt.xlabel(xlabel, fontsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8, 8))\n",
    "\n",
    "conf_matrix_gbm = metrics.confusion_matrix(lbls, pred)\n",
    "plot_confusion_matrix(conf_matrix_gbm, \n",
    "                      classes=[class_names[idx - 1] for idx in class_labels], \n",
    "                      normalize=True, \n",
    "                      ylabel='Truth (LAND COVER)', \n",
    "                      xlabel='Predicted (GBM)',\n",
    "                      title='Confusion matrix');\n",
    "\n",
    "fig.savefig(f'figs/ConfusionMatrix.png', bbox_inches='tight')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](figs/ConfusionMatrix.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8, 8))\n",
    "\n",
    "conf_matrix_gbm = metrics.confusion_matrix(pred, lbls)\n",
    "plot_confusion_matrix(conf_matrix_gbm, \n",
    "                      classes=[class_names[idx - 1] for idx in class_labels], \n",
    "                      normalize=True, \n",
    "                      xlabel='Truth (LAND COVER)', \n",
    "                      ylabel='Predicted (GBM)',\n",
    "                      title='Transposed Confusion matrix');\n",
    "fig.savefig(f'figs/Transposed ConfusionMatrix.png', bbox_inches='tight')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](figs/TransposedConfusionMatrix.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How often do the classes appear in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20, 5))\n",
    "\n",
    "label_ids, label_counts = np.unique(labels_train, return_counts=True)\n",
    "\n",
    "plt.bar(range(len(label_ids)), label_counts)\n",
    "plt.xticks(range(len(label_ids)), [class_names[i -1] for i in label_ids], rotation=45, fontsize=15);\n",
    "plt.yticks(fontsize=20);\n",
    "fig.savefig(f'figs/labels_count.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image](figs/label_count.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AUC-ROC curves and  metrics\n",
    "\n",
    "Calculate precision and recall rates, draw (Receiver Operating Characteristic) ROC curves  and calculate (Area Under The Curve) AUC. Also known as AUROC (Area Under the Receiver Operating Characteristics). ROC is a probability curve and AUC represents degree or measure of separability. \n",
    "\n",
    "AUC - ROC curve is a performance measurement for classification problems at various thresholds settings. It tells how much model is capable of distinguishing between classes. The reader is refered to [here](https://towardsdatascience.com/understanding-auc-roc-curve-68b2303cc9c5)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_labels = np.unique(np.hstack([labels_test, labels_train]))\n",
    "\n",
    "scores_test = model.predict_proba(features_test)\n",
    "labels_binarized = preprocessing.label_binarize(labels_test, classes=class_labels)\n",
    "\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "\n",
    "for idx,lbl in enumerate(class_labels):\n",
    "    fpr[idx -1], tpr[idx -1], _ = metrics.roc_curve(labels_binarized[:, idx], scores_test[:, idx])\n",
    "    roc_auc[idx -1] = metrics.auc(fpr[idx -1], tpr[idx -1])   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "\n",
    "for idx,lbl in enumerate(class_labels):\n",
    "    if np.isnan(roc_auc[idx -1]):\n",
    "        continue\n",
    "    plt.plot(fpr[idx -1], tpr[idx -1], color=lulc_cmap.colors[lbl -1],\n",
    "         lw=2, label=class_names[lbl -1] + ' (%0.5f)' % roc_auc[idx -1])\n",
    "    \n",
    "\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 0.99])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate', fontsize=20)\n",
    "plt.ylabel('True Positive Rate', fontsize=20)\n",
    "plt.xticks(fontsize=20)\n",
    "plt.yticks(fontsize=20)\n",
    "plt.title('ROC Curve', fontsize=20)\n",
    "plt.legend(loc=\"lower right\", prop={'size': 13})\n",
    "fig.savefig(f'figs/roc_curve.png', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image](figs/roc_curve.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Most important features\n",
    "\n",
    "Let us now check which features are most important in the above classification. The LightGBM model already contains the information about feature importances, so we only need to query them. This functionality would be more effective with a larger time-series. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# names of features\n",
    "fnames = ['B2','B3','B4','B8','B11','B12','NDVI','NDWI','NDBI']\n",
    "\n",
    "# get feature importances and reshape them to dates and features\n",
    "feature_importances = model.feature_importances_.reshape((t, f))\n",
    "\n",
    "fig = plt.figure(figsize=(15, 15))\n",
    "ax = plt.gca()\n",
    "\n",
    "# plot the importances\n",
    "im = ax.imshow(feature_importances, aspect=0.25)\n",
    "plt.xticks(range(len(fnames)), fnames, rotation=45, fontsize=20)\n",
    "plt.yticks(range(t), [f'T{i}' for i in range(t)], fontsize=20)\n",
    "plt.xlabel('Bands and band related features', fontsize=20)\n",
    "plt.ylabel('Time frames', fontsize=20)\n",
    "ax.xaxis.tick_top()\n",
    "ax.xaxis.set_label_position('top') \n",
    "\n",
    "fig.subplots_adjust(wspace=0, hspace=0)\n",
    "\n",
    "cb = fig.colorbar(im, ax=[ax], orientation='horizontal', pad=0.01, aspect=100)\n",
    "cb.ax.tick_params(labelsize=20)\n",
    "fig.savefig(f'figs/bands_and_features.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image](figs/bands_and_features.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
